{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on using word-to-analyses-freq lexicons for reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os, os.path\n",
    "from estnltk.converters import json_to_text\n",
    "from estnltk.taggers import MorphAnalysisReorderer\n",
    "\n",
    "from eval_utils import GoldStandard\n",
    "from eval_utils import add_normalized_form_to_words\n",
    "from eval_utils import collect_matches\n",
    "from eval_utils import write_out_freq_sorted_annotations\n",
    "from eval_utils import evaluate_reorderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus with gold standard annotations\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lexicons based on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded and pre-annotated  et_edt-ud-train_000.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_001.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_002.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_003.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_004.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_005.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_006.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_007.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_008.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_009.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_010.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_011.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_012.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_013.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_014.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_015.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_016.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_017.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_018.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_019.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_020.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_021.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_022.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_023.json\n"
     ]
    }
   ],
   "source": [
    "# Load gold standard texts and add pre-annotations\n",
    "loaded_texts = []\n",
    "for fname in os.listdir( input_dir ):\n",
    "    if 'dev' in fname:\n",
    "        continue\n",
    "    if 'test' in fname:\n",
    "        continue\n",
    "    if fname.endswith('.json'):\n",
    "        # Load Text with gold standard annotations\n",
    "        text = json_to_text(file=os.path.join(input_dir, fname) )\n",
    "        if 'normalized_form' not in text.words.attributes:\n",
    "            add_normalized_form_to_words( text.words )\n",
    "        assert 'normalized_form' in text.words.attributes\n",
    "        # Add Vabamorf's default morph analysis\n",
    "        text.tag_layer(['morph_analysis'])\n",
    "        loaded_texts.append( text )\n",
    "        print(' Loaded and pre-annotated ', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processed documents:                                 24\n",
      " Ambiguous words from total words:                    28766 / 344646 (8.35%)\n",
      " Ambiguous words successfully matched to gold morph:  26929 / 28766 (93.61%)\n"
     ]
    }
   ],
   "source": [
    "focus_fields = ['lemma','ending','clitic','partofspeech','form']\n",
    "word_matches = collect_matches( loaded_texts, 'ud_morph_reduced', \n",
    "                                gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                                focus_fields = focus_fields )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include all analyses\n",
    "write_out_freq_sorted_annotations( 'et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                   word_matches, focus_fields, \n",
    "                                   freq_threshold=-1, encoding='utf-8' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include analyses at freq threshold 5\n",
    "write_out_freq_sorted_annotations( 'et_edt-ud-train_sorted_analyses_cut_5.csv', \n",
    "                                    word_matches, focus_fields, \n",
    "                                    freq_threshold=5, encoding='utf-8' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lexicons based on train+dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded and pre-annotated  et_edt-ud-dev_000.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_001.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_002.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_003.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_004.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_005.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_006.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_007.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_008.json\n"
     ]
    }
   ],
   "source": [
    "assert loaded_texts and len(loaded_texts) > 0\n",
    "# Add dev data to loaded_texts\n",
    "for fname in os.listdir( input_dir ):\n",
    "    if 'train' in fname:\n",
    "        continue\n",
    "    if 'test' in fname:\n",
    "        continue\n",
    "    if fname.endswith('.json'):\n",
    "        # Load Text with gold standard annotations\n",
    "        text = json_to_text(file=os.path.join(input_dir, fname) )\n",
    "        if 'normalized_form' not in text.words.attributes:\n",
    "            add_normalized_form_to_words( text.words )\n",
    "        assert 'normalized_form' in text.words.attributes\n",
    "        # Add Vabamorf's default morph analysis\n",
    "        text.tag_layer(['morph_analysis'])\n",
    "        loaded_texts.append( text )\n",
    "        print(' Loaded and pre-annotated ', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processed documents:                                 33\n",
      " Ambiguous words from total words:                    32510 / 389278 (8.35%)\n",
      " Ambiguous words successfully matched to gold morph:  30440 / 32510 (93.63%)\n"
     ]
    }
   ],
   "source": [
    "focus_fields = ['lemma','ending','clitic','partofspeech','form']\n",
    "word_matches = collect_matches( loaded_texts, 'ud_morph_reduced', \n",
    "                                gold_morph_type=GoldStandard.UD_CORPUS,\n",
    "                                focus_fields = focus_fields )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include all analyses\n",
    "write_out_freq_sorted_annotations( 'et_edt-ud-train_and_dev_sorted_analyses_full.csv', \n",
    "                                   word_matches, focus_fields, \n",
    "                                   freq_threshold=-1, encoding='utf-8' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include analyses at freq threshold 5\n",
    "write_out_freq_sorted_annotations( 'et_edt-ud-train_and_dev_sorted_analyses_cut_5.csv', \n",
    "                                    word_matches, focus_fields, \n",
    "                                    freq_threshold=5, encoding='utf-8' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A small test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mail</td>\n",
       "      <td>mail</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>il</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('mail', [{'normalized_text': 'mail', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'il', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}, {'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span('üks', [{'normalized_text': 'üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'N'}, {'normalized_text': 'üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example text\n",
    "from estnltk import Text\n",
    "t=Text('See toimus 1. mail, ütles üks.').tag_layer(['morph_analysis'])\n",
    "\n",
    "# Output ambiguities\n",
    "t.morph_analysis[lambda x : len(x.annotations) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mail</td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mail</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>il</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('mail', [{'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}, {'normalized_text': 'mail', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'il', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}]),\n",
       "Span('üks', [{'normalized_text': 'üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}, {'normalized_text': 'üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'N'}])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to ordering\n",
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "morph_reorderer.retag( t )\n",
    "\n",
    "# Output ambiguities\n",
    "t.morph_analysis[lambda x : len(x.annotations) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data: train || eval data: dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 9 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           3744\n",
      "   -- correct analysis first:      1762 / 3744 (47.06%)\n",
      "   -- correct analysis not first:  1781 / 3744 (47.57%)\n",
      "   -- correct analysis not found:  233 / 3744 (6.22%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           3744\n",
      "   -- correct analysis first:      2772 / 3744 (74.04%)\n",
      "   -- correct analysis not first:  771 / 3744 (20.59%)\n",
      "   -- correct analysis not found:  233 / 3744 (6.22%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  1762 / 3744 (47.06%) ==> 2772 / 3744 (74.04%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                    exclude_strs=['train', 'test'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 9 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           3744\n",
      "   -- correct analysis first:      1762 / 3744 (47.06%)\n",
      "   -- correct analysis not first:  1781 / 3744 (47.57%)\n",
      "   -- correct analysis not found:  233 / 3744 (6.22%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           3744\n",
      "   -- correct analysis first:      2715 / 3744 (72.52%)\n",
      "   -- correct analysis not first:  828 / 3744 (22.12%)\n",
      "   -- correct analysis not found:  233 / 3744 (6.22%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  1762 / 3744 (47.06%) ==> 2715 / 3744 (72.52%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_sorted_analyses_cut_5.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                    exclude_strs=['train', 'test'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data: train || eval data: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4170\n",
      "   -- correct analysis first:      2131 / 4170 (51.10%)\n",
      "   -- correct analysis not first:  1887 / 4170 (45.25%)\n",
      "   -- correct analysis not found:  204 / 4170 (4.89%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4170\n",
      "   -- correct analysis first:      3069 / 4170 (73.60%)\n",
      "   -- correct analysis not first:  949 / 4170 (22.76%)\n",
      "   -- correct analysis not found:  204 / 4170 (4.89%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2131 / 4170 (51.10%) ==> 3069 / 4170 (73.60%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4170\n",
      "   -- correct analysis first:      2131 / 4170 (51.10%)\n",
      "   -- correct analysis not first:  1887 / 4170 (45.25%)\n",
      "   -- correct analysis not found:  204 / 4170 (4.89%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4170\n",
      "   -- correct analysis first:      3040 / 4170 (72.90%)\n",
      "   -- correct analysis not first:  978 / 4170 (23.45%)\n",
      "   -- correct analysis not found:  204 / 4170 (4.89%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2131 / 4170 (51.10%) ==> 3040 / 4170 (72.90%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_sorted_analyses_cut_5.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS,\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data: train and dev || eval data: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4170\n",
      "   -- correct analysis first:      2131 / 4170 (51.10%)\n",
      "   -- correct analysis not first:  1887 / 4170 (45.25%)\n",
      "   -- correct analysis not found:  204 / 4170 (4.89%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4170\n",
      "   -- correct analysis first:      3075 / 4170 (73.74%)\n",
      "   -- correct analysis not first:  943 / 4170 (22.61%)\n",
      "   -- correct analysis not found:  204 / 4170 (4.89%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2131 / 4170 (51.10%) ==> 3075 / 4170 (73.74%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_and_dev_sorted_analyses_full.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4170\n",
      "   -- correct analysis first:      2131 / 4170 (51.10%)\n",
      "   -- correct analysis not first:  1887 / 4170 (45.25%)\n",
      "   -- correct analysis not found:  204 / 4170 (4.89%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4170\n",
      "   -- correct analysis first:      3044 / 4170 (73.00%)\n",
      "   -- correct analysis not first:  974 / 4170 (23.36%)\n",
      "   -- correct analysis not found:  204 / 4170 (4.89%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2131 / 4170 (51.10%) ==> 3044 / 4170 (73.00%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_and_dev_sorted_analyses_cut_5.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "           lexicon file:                               eval: dev              eval: test\n",
    "\n",
    "    et_edt-ud-train_sorted_analyses_full.csv       47.06% --> 74.04%       51.10% -> 73.60%\n",
    "                                                   (+26.98)               (+22.5)\n",
    "\n",
    "    et_edt-ud-train_sorted_analyses_cut_5.csv      47.06% --> 72.52%       51.10% -> 72.90%\n",
    "                                                   (+25.46)               (+21.8)\n",
    "\n",
    "    et_edt-ud-train_and_dev_sorted_analyses_full.csv    --------           51.10% -> 73.74%\n",
    "                                                                          (+22.64)\n",
    "\n",
    "    et_edt-ud-train_and_dev_sorted_analyses_cut_5.csv   --------           51.10% -> 73.00%\n",
    "                                                                          (+21.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
